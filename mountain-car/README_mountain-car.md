# Mountain Car

This folder contains code for solving the **MountainCar** control task using reinforcement learning (e.g., SARSA/Qâ€‘Learning) with **tile coding** function approximation.

## ğŸ“ Structure

```
mountain-car/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tile_coding.py     # IHT / tiles implementation
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ agents/                # SARSA / Q-Learning agents (tile-coded value function)
â”œâ”€â”€ experiments/           # Training & evaluation scripts
â”œâ”€â”€ utils/                 # Plotting, logging, helpers
â”œâ”€â”€ results/               # Saved runs, metrics, figures
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Setup

1) Install dependencies:

```bash
pip install -r requirements.txt
```

2) (Optional) Create a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
.venv\Scripts\activate     # Windows
```

## ğŸš€ How to Run

Train an agent on MountainCarâ€‘v0:

```bash
python experiments/train_mountain_car.py   --env MountainCar-v0   --episodes 500   --alpha 0.1   --gamma 0.99   --epsilon 0.0   --n-tiles 8   --n-tilings 8
```

Evaluate a trained model:

```bash
python experiments/evaluate_mountain_car.py --model_path results/best_model.pth
```

Plot learning curves / returns:

```bash
python utils/plot_results.py --input_dir results/ --output_fig mountain_car.png
```

## ğŸ”§ Notes

- Uses **tile coding** (`src/tile_coding.py`) to approximate the value function over continuous state (position, velocity).
- Supports standard control updates: **SARSA**, **Qâ€‘Learning**, **Expected SARSA** (if implemented in `agents/`).
- Typical hyperparameters:
  - `--alpha` (learning rate), `--gamma` (discount), `--epsilon` (Îµâ€‘greedy)
  - `--n-tiles`, `--n-tilings` (tile coding resolution)
- Results (logs, metrics, plots) are stored in `results/`.

