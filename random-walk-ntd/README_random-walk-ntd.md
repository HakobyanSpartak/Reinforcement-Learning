# Random Walk (Nâ€‘TD)

This folder contains code for the **Random Walk** problem using **nâ€‘step Temporal Difference (Nâ€‘TD)** methods in reinforcement learning.

The purpose is to explore how different *n* steps in TD methods affect learning speed, biasâ€“variance tradeoff, and prediction accuracy.

---

## ğŸ“ Structure

```
random-walk-ntd/
â”œâ”€â”€ envs/             # Environment implementation (random walk dynamics)
â”œâ”€â”€ agents/           # Agent algorithms implementing nâ€‘step TD
â”œâ”€â”€ experiments/      # Scripts to train and evaluate agents with various n
â”œâ”€â”€ utils/            # Helper functions: plotting, monitoring, logging
â”œâ”€â”€ results/          # Outputs: metrics, saved models, plots
â”œâ”€â”€ requirements.txt  # Python dependencies
â””â”€â”€ README.md         # This file
```

---

## âš™ï¸ Setup & Requirements

1. Install dependencies:

```bash
pip install -r requirements.txt
```

2. (Optional) Use a virtual environment to isolate dependencies:

```bash
python -m venv .venv
source .venv/bin/activate     # macOS / Linux
.venv\Scripts\activate       # Windows
```

---

## ğŸš€ How to Run / Usage

To train an agent using nâ€‘step TD:

```bash
python experiments/train_ntd.py --n 3 --episodes 1000 --alpha 0.1 --gamma 0.9
```

To evaluate a trained model:

```bash
python experiments/evaluate_ntd.py --model_path results/best_model.pth
```

You can adjust hyperparameters via flags:

- `--n` â€” number of steps in Nâ€‘TD
- `--episodes` â€” number of training episodes
- `--alpha` â€” learning rate
- `--gamma` â€” discount factor

---

## ğŸ“Š Visualization

After training, use utility scripts to plot learning curves, error vs. episodes, or compare different-step results:

```bash
python utils/plot_results.py --input_dir results/ --output_fig ntd_comparison.png
```

---

## ğŸ¯ Purpose & Notes

The **nâ€‘step TD** method generalizes between Monte Carlo (large n) and one-step TD (n = 1).
This project studies how choosing different *n* values influences:

- Convergence speed
- Bias and variance of value estimates
- Stability in training

You can add experiments for new *n* values or compare with other methods (e.g. TD(Î»)) by extending `experiments/` or `agents/`.


**Author / Maintainer:** [Hakobyan Spartak](https://github.com/HakobyanSpartak)
